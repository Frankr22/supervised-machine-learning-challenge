{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Frankr22/supervised-machine-learning-challenge/blob/main/Credit_Risk_Evaluator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkvQWmuf55u-"
      },
      "source": [
        "# Credit Risk Evaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jlsc_Owe55vA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2PInxhp55vB"
      },
      "source": [
        "## Retrieve the Data\n",
        "\n",
        "The data is located in the Challenge Files Folder:\n",
        "\n",
        "* `lending_data.csv`\n",
        "\n",
        "Import the data using Pandas. Display the resulting dataframe to confirm the import was successful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3netnQ255vC",
        "outputId": "c1c60ed7-655d-49c8-91a9-86c04fc05215"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   loan_size  interest_rate  borrower_income  debt_to_income  num_of_accounts  \\\n",
            "0    10700.0          7.672            52800        0.431818                5   \n",
            "1     8400.0          6.692            43600        0.311927                3   \n",
            "2     9000.0          6.963            46100        0.349241                3   \n",
            "3    10700.0          7.664            52700        0.430740                5   \n",
            "4    10800.0          7.698            53000        0.433962                5   \n",
            "\n",
            "   derogatory_marks  total_debt  loan_status  \n",
            "0                 1       22800            0  \n",
            "1                 0       13600            0  \n",
            "2                 0       16100            0  \n",
            "3                 1       22700            0  \n",
            "4                 1       23000            0  \n"
          ]
        }
      ],
      "source": [
        "# Import the data\n",
        "# Load data from CSV file\n",
        "lending_data = pd.read_csv(\"Resources/lending_data.csv\")\n",
        "\n",
        "# Display the dataframe\n",
        "print(lending_data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjEalPx_55vC"
      },
      "source": [
        "## Predict Model Performance\n",
        "\n",
        "You will be creating and comparing two models on this data: a Logistic Regression, and a Random Forests Classifier. Before you create, fit, and score the models, make a prediction as to which model you think will perform better. You do not need to be correct! \n",
        "\n",
        "Write down your prediction in the designated cells in your Jupyter Notebook, and provide justification for your educated guess."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQo-tDv455vC"
      },
      "source": [
        "My prediction is that the Random Forest Classifier might perform better in this case, as there could be non-linear relationships between the features that affect the loan status."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMzd475C55vC"
      },
      "source": [
        "## Split the Data into Training and Testing Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EkhJC2-h55vC"
      },
      "outputs": [],
      "source": [
        "# Split the data into X_train, X_test, y_train, y_test\n",
        "\n",
        "# Split the data into features (X) and labels (y)\n",
        "X = lending_data.drop(\"loan_status\", axis=1)\n",
        "y = lending_data[\"loan_status\"]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDckQ57755vD"
      },
      "source": [
        "## Create, Fit and Compare Models\n",
        "\n",
        "Create a Logistic Regression model, fit it to the data, and print the model's score. Do the same for a Random Forest Classifier. You may choose any starting hyperparameters you like. \n",
        "\n",
        "Which model performed better? How does that compare to your prediction? Write down your results and thoughts in the designated markdown cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XStQLe2-55vD",
        "outputId": "1905e069-2be5-4e27-a67f-8027a9c1aa86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression model score: 0.992\n"
          ]
        }
      ],
      "source": [
        "# Train a Logistic Regression model and print the model score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Create a Logistic Regression model\n",
        "lr_model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "\n",
        "# Fit the model to the training data\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Print the model score on the testing data\n",
        "print(\"Logistic Regression model score: {:.3f}\".format(lr_model.score(X_test, y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30dQcWRt55vD",
        "outputId": "d7056bb9-6311-4c06-98b4-ab30200ac29d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier model score: 0.991\n"
          ]
        }
      ],
      "source": [
        "# Train a Random Forest Classifier model and print the model score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create a Random Forest Classifier model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=1)\n",
        "\n",
        "# Fit the model to the training data\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Print the model score on the testing data\n",
        "print(\"Random Forest Classifier model score: {:.3f}\".format(rf_model.score(X_test, y_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lY3eZ92G55vD"
      },
      "source": [
        "The Logistic Regression model performed slightly better than the Random Forest Classifier model, with a score of 0.992 compared to 0.991 for the Random Forest Classifier model. This result is contrary to my previous prediction, as the Logistic Regression model would typically perform better when the features are linearly separable, which appears to be the case in this dataset."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}